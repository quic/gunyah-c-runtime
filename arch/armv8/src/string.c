// Â© 2021 Qualcomm Innovation Center, Inc. All rights reserved.
//
// SPDX-License-Identifier: BSD-3-Clause

#include <assert.h>
#include <stdint.h>
#include <string.h>

#include <asm/cpu.h>
#include <asm/prefetch.h>

#include <compiler.h>
#include <errno.h>

// Assembly functions. All of these come in at least three variants:
//
// - _align16 for at least 16 bytes with target known to be 16-aligned;
// - _alignable for at least 31 bytes with unknown target alignment;
// - _below32 for less than 32 bytes (i.e. one access of each size).
//
// Note the overlap between _alignable and _below32 at n==31; either variant
// may be used at that size. We use _below32 because the logic to trigger its
// first 16-byte copy is simpler.
//
// For memset to zero there is additionally a _dczva variant, where the target
// is aligned to a DC ZVA block (typically a 64-byte cache line) and is at
// least that size.
//
// The variants other than _below32 fall through to the more-aligned versions
// once the necessary alignment has been established.

// TODO: Clang does only simple constant propagation when LTO is enabled,
// preferring to leave it until LTO. However, the LLVM IR has no way to
// represent __builtin_constant_p(). So it is not really possible to use
// __builtin_constant_p() here to avoid runtime checks, since it will nearly
// always evaluate to 0.
//
// To make any static assertions or build-time variant selection actually
// effective, we need to move all of the definitions below into inlines in a
// header. We would then need to either include it here to generate extern
// definitions for the backend to use, or else define them in the assembly.

void
memcpy_below32(void *restrict s1, const void *restrict s2, size_t n);

void
memcpy_alignable(void *restrict s1, const void *restrict s2, size_t n);

void
memcpy_align16(void *restrict s1, const void *restrict s2, size_t n);

void
memcpy_bytes(void *restrict s1, const void *restrict s2, size_t n);

void
memset_zeros_alignable(void *s, size_t n);

void
memset_zeros_below32(void *s, size_t n);

void
memset_zeros_align16(void *s, size_t n);

void
memset_zeros_dczva(void *s, size_t n);

void
memset_alignable(void *s, uint8_t c, size_t n);

void
memset_below32(void *s, uint64_t cs, size_t n);

void
memset_align16(void *s, uint64_t cs, size_t n);

void *
memcpy(void *restrict s1, const void *restrict s2, size_t n)
{
	assert(compiler_sizeof_object(s1) >= n);
	assert(compiler_sizeof_object(s2) >= n);
	if (n == 0UL) {
		// Nothing to do.
	} else if (n < 32UL) {
		prefetch_store_keep(s1);
		prefetch_load_stream(s2);
		memcpy_below32(s1, s2, n);
	} else {
		prefetch_store_keep(s1);
		prefetch_load_stream(s2);
		uintptr_t a16 = (uintptr_t)s1 & (uintptr_t)15;
		if (a16 == 0UL) {
			memcpy_align16(s1, s2, n);
		} else {
			memcpy_alignable(s1, s2, n);
		}
	}

	return s1;
}

void *
memmove(void *s1, const void *s2, size_t n)
{
	// The hypervisor should never need memmove(), but unfortunately the
	// test program won't link if we don't define it. This is because
	// static glibc defines it in the same object as memcpy(), so if we
	// don't define it the calls in the glibc startup will pull in the
	// glibc version of memcpy() and cause duplicate definition errors.
	//
	// In cases where we know our fast memcpy will work, just call that.
	// Otherwise call a slow memcpy which is only defined in the test
	// program.
	if ((uintptr_t)s1 == (uintptr_t)s2) {
		// Nothing to do.
	} else if ((uintptr_t)s1 < (uintptr_t)s2) {
		(void)memcpy(s1, s2, n);
	} else if ((uintptr_t)s2 + CPU_MEMCPY_STRIDE < (uintptr_t)s1) {
		(void)memcpy(s1, s2, n);
	} else if (((uintptr_t)s1 + n <= (uintptr_t)s2) &&
		   ((uintptr_t)s2 + n <= (uintptr_t)s1)) {
		(void)memcpy(s1, s2, n);
	} else {
		(void)memcpy_bytes(s1, s2, n);
	}
	return s1;
}

void *
memset(void *s, int c, size_t n)
{
	assert(compiler_sizeof_object(s) >= n);
	uintptr_t a16 = (uintptr_t)s & (uintptr_t)15;

	if (n == 0UL) {
		// Nothing to do.
	} else if (c == 0) {
		uintptr_t a_zva = (uintptr_t)s &
				  (uintptr_t)((1UL << CPU_DCZVA_BITS) - 1UL);
		if (n < 32UL) {
			prefetch_store_keep(s);
			memset_zeros_below32(s, n);
		} else if ((a_zva == 0UL) && ((n >> CPU_DCZVA_BITS) > 0UL)) {
			memset_zeros_dczva(s, n);
		} else if (a16 == 0UL) {
			prefetch_store_keep(s);
			memset_zeros_align16(s, n);
		} else {
			prefetch_store_keep(s);
			memset_zeros_alignable(s, n);
		}
	} else {
		uint64_t cs = (uint64_t)(uint8_t)c;
		cs |= cs << 8;
		cs |= cs << 16;
		cs |= cs << 32;
		if (n < 32UL) {
			prefetch_store_keep(s);
			memset_below32(s, cs, n);
		} else if (a16 == 0UL) {
			prefetch_store_keep(s);
			memset_align16(s, cs, n);
		} else {
			prefetch_store_keep(s);
			memset_alignable(s, (uint8_t)c, n);
		}
	}

	return s;
}

void *
memchr(const void *s, int c, size_t n)
{
	const unsigned char *ret = NULL;

	const unsigned char *str   = s;
	unsigned char	     delim = (unsigned char)c;

	size_t remain = n;

	while (remain > 0UL) {
		if (*str == delim) {
			ret = str;
			break;
		}
		str++;
		remain--;
	}

	// Std C function forces cast to non-const
	return (void *)(uintptr_t)ret;
}

size_t
strlen(const char *str)
{
	const char *end = str;

	assert(str != NULL);

	for (; *end != '\0'; end++) {
	}

	return (size_t)((uintptr_t)end - (uintptr_t)str);
}

ssize_t
strscpy(char *dest, const char *str, size_t count)
{
	char	   *out	   = dest;
	const char *pos	   = str;
	size_t	    remain = count;
	ssize_t	    ret;

	if (count == 0UL) {
		ret = -E2BIG;
		goto out;
	}

	while ((*pos != '\0') && (remain > 1UL)) {
		*out = *pos;
		out++;
		pos++;
		remain--;
	}
	*out = '\0';

	if (*pos != '\0') {
		ret = -E2BIG;
	} else {
		ret = (ssize_t)count - (ssize_t)remain;
	}

out:
	return ret;
}
